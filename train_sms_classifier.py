# =================================================================================
# FILE: train_sms_classifier.py
# REASON: This script handles the offline training and conversion of the SMS
# text classification model. It loads the dataset generated by the :analyzer
# module, builds and trains a TensorFlow/Keras model, evaluates its performance,
# and exports the final, quantized .tflite model and its associated vocabulary
# file for use in the Android application.
#
# REFACTOR: The model architecture has been changed to remove the TextVectorization
# layer from the model itself. The script now pre-processes the text data *before*
# training and exports a model that accepts a simple integer array as input.
# This makes the model more portable and removes the dependency on the TFLite Flex
# delegate for on-device string processing, resolving stubborn test failures.
#
# DEBUG: Added a new `debug_on_device_failure` function to print the exact
# preprocessed output for specific SMS messages. This provides a ground-truth
# reference to ensure the on-device Kotlin implementation matches perfectly.
#
# REFACTOR: The TextVectorization layer now uses an explicit custom standardization
# function. This removes any ambiguity about the text cleaning process and makes
# it easier to replicate perfectly in the on-device Kotlin code.
# =================================================================================

import os
import re
import string
import pandas as pd
import tensorflow as tf
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report

# Suppress TensorFlow logging for a cleaner output.
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'

# --- Configuration ---
DATASET_PATH = "training_data.csv"
VOCAB_SIZE = 10000  # Max number of unique words to consider.
MAX_SEQUENCE_LENGTH = 250  # Max length of an SMS to consider.
EMBEDDING_DIM = 16  # Dimension for word embeddings.
MODEL_OUTPUT_DIR = "sms_classifier_model"
TFLITE_MODEL_NAME = "sms_classifier.tflite"
VOCAB_FILE_NAME = "vocab.txt"


def load_and_prepare_data(path):
    """Loads the CSV dataset and splits it into training and testing sets."""
    print(f"\n--- Loading dataset from: {path} ---")
    try:
        df = pd.read_csv(path)
    except FileNotFoundError:
        print(f"Error: Dataset file not found at '{path}'.")
        print("Please make sure 'training_data.csv' is in the same directory as this script.")
        return None, None, None, None

    # Handle potential missing values
    df['text'] = df['text'].fillna('')

    print(f"Dataset loaded successfully. Total samples: {len(df)}")
    print(f"Class distribution:\n{df['label'].value_counts(normalize=True)}")

    # Split the data
    X = df['text'].values
    y = df['label'].values
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)
    print(f"Data split into {len(X_train)} training samples and {len(X_test)} testing samples.")
    return X_train, X_test, y_train, y_test


def custom_standardization(input_data):
    """A custom standardization function that mirrors the Keras default."""
    lowercase = tf.strings.lower(input_data)
    # The [..] brackets in the regex create a character set.
    # re.escape ensures that special characters in string.punctuation are treated literally.
    return tf.strings.regex_replace(lowercase, '[%s]' % re.escape(string.punctuation), '')


def build_and_train_model(X_train, y_train, X_test, y_test):
    """Builds, trains, and returns the text classification model and its vectorization layer."""
    print("\n--- Preprocessing Text Data ---")

    # 1. Create and adapt the TextVectorization layer using our explicit function.
    vectorize_layer = tf.keras.layers.TextVectorization(
        standardize=custom_standardization,
        max_tokens=VOCAB_SIZE,
        output_mode='int',
        output_sequence_length=MAX_SEQUENCE_LENGTH
    )
    vectorize_layer.adapt(X_train)
    print("TextVectorization layer created and adapted with custom standardization.")

    # 2. Pre-process the training and testing text data into integer sequences.
    X_train_vec = vectorize_layer(X_train)
    X_test_vec = vectorize_layer(X_test)
    print("Text data has been vectorized.")

    # 3. Build the model architecture to accept integer sequences.
    model = tf.keras.Sequential([
        tf.keras.layers.Input(shape=(MAX_SEQUENCE_LENGTH,), dtype=tf.int64),
        tf.keras.layers.Embedding(VOCAB_SIZE, EMBEDDING_DIM, name="embedding"),
        tf.keras.layers.GlobalAveragePooling1D(),
        tf.keras.layers.Dense(16, activation='relu'),
        tf.keras.layers.Dropout(0.5),
        tf.keras.layers.Dense(1, activation='sigmoid')
    ])

    # 4. Compile the model.
    model.compile(optimizer='adam',
                  loss='binary_crossentropy',
                  metrics=['accuracy'])
    model.summary()

    # 5. Train the model using the vectorized data.
    print("\nStarting training...")
    history = model.fit(
        X_train_vec,
        y_train,
        epochs=5,
        validation_data=(X_test_vec, y_test),
        verbose=1
    )
    print("Training complete.")
    return model, vectorize_layer, X_test_vec


def evaluate_model(model, X_test_vec, y_test):
    """Evaluates the model's performance on the vectorized test set."""
    print("\n--- Evaluating model performance ---")
    loss, accuracy = model.evaluate(X_test_vec, y_test, verbose=0)
    print(f"Test Accuracy: {accuracy:.4f}")

    # Generate a detailed classification report
    y_pred_probs = model.predict(X_test_vec, verbose=0)
    y_pred = (y_pred_probs > 0.5).astype("int32")
    print("\nClassification Report:")
    print(classification_report(y_test, y_pred, target_names=['NON_TRANSACTION (0)', 'TRANSACTION (1)']))


def export_model_and_vocab(model, vectorize_layer):
    """Saves the model, converts it to TFLite, and exports the vocabulary."""
    print("\n--- Exporting model and vocabulary ---")

    # 1. Create the output directory if it doesn't exist.
    if not os.path.exists(MODEL_OUTPUT_DIR):
        os.makedirs(MODEL_OUTPUT_DIR)

    # 2. Convert the Keras model to a concrete function for TFLite conversion.
    run_model = tf.function(lambda x: model(x))
    concrete_func = run_model.get_concrete_function(
        tf.TensorSpec([None, MAX_SEQUENCE_LENGTH], model.inputs[0].dtype)
    )

    # 3. Convert the model to TensorFlow Lite with quantization.
    converter = tf.lite.TFLiteConverter.from_concrete_functions([concrete_func])
    converter.optimizations = [tf.lite.Optimize.DEFAULT]
    tflite_model = converter.convert()

    # 4. Save the TFLite model.
    tflite_model_path = os.path.join(MODEL_OUTPUT_DIR, TFLITE_MODEL_NAME)
    with open(tflite_model_path, 'wb') as f:
        f.write(tflite_model)
    print(f"Optimized TFLite model saved to: {tflite_model_path} ({len(tflite_model) / 1024:.2f} KB)")

    # 5. Export the vocabulary from the TextVectorization layer.
    vocab = vectorize_layer.get_vocabulary()
    vocab_file_path = os.path.join(MODEL_OUTPUT_DIR, VOCAB_FILE_NAME)
    with open(vocab_file_path, 'w', encoding='utf-8') as f:
        for word in vocab:
            f.write(f"{word}\n")
    print(f"Vocabulary file saved to: {vocab_file_path}")

def debug_on_device_failure(vectorize_layer):
    """A helper function to see exactly how the vectorizer processes failing SMS messages."""
    failing_sms_1 = "You've spent Rs.349 On HDFC Bank CREDIT Card xx1455 At RAZ*StickON..."
    failing_sms_2 = "Your A/C XXXXX436715 has credit for BY SALARY of Rs 1,161.00 on 16/11/21."

    print("\n--- DEBUGGING ANDROID TEST FAILURE ---")
    for i, sms in enumerate([failing_sms_1, failing_sms_2]):
        cleaned_text = custom_standardization(tf.constant([sms]))
        vectorized_output = vectorize_layer([sms])
        print(f"\n--- Failing SMS #{i+1} ---")
        print(f"Original String : {sms}")
        print(f"Cleaned String  : {cleaned_text.numpy()[0].decode('utf-8')}")
        # Only print the first 30 tokens for brevity
        print(f"Vectorized (int): {vectorized_output.numpy()[0][:30]}...")
    print("--------------------------------------")


def main():
    """Main function to run the entire workflow."""
    X_train, X_test, y_train, y_test = load_and_prepare_data(DATASET_PATH)

    if X_train is None:
        return

    model, vectorize_layer, X_test_vec = build_and_train_model(X_train, y_train, X_test, y_test)
    evaluate_model(model, X_test_vec, y_test)
    export_model_and_vocab(model, vectorize_layer)

    # Run the debug function to see the ground truth
    # debug_on_device_failure(vectorize_layer)

    print("\nâœ… All steps completed successfully!")
    print(f"Your model ('{TFLITE_MODEL_NAME}') and vocabulary ('{VOCAB_FILE_NAME}') are in the '{MODEL_OUTPUT_DIR}' directory.")


if __name__ == '__main__':
    main()